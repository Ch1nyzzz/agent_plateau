{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vLLM 离线推理示例\n",
    "\n",
    "这个 notebook 展示如何使用 vLLM 离线推理（无需启动服务器）来运行 benchmark 评估。\n",
    "\n",
    "## 优势\n",
    "- ✅ 无需启动和管理 vLLM 服务器\n",
    "- ✅ 自动批处理，更高效的数据并行\n",
    "- ✅ 更低的延迟（无网络开销）\n",
    "- ✅ 完全兼容 DSPy 和 GEPA\n",
    "\n",
    "## 对比：服务器模式 vs 离线模式\n",
    "\n",
    "| 特性 | 服务器模式 | 离线模式 |\n",
    "|------|------------|----------|\n",
    "| 启动方式 | 需要先运行 `bash start_vllm.sh` | 直接在代码中加载 |\n",
    "| 网络开销 | 有（HTTP 请求） | 无 |\n",
    "| 并行推理 | 需手动管理并发 | 自动批处理 |\n",
    "| 资源占用 | 服务器 + 客户端 | 仅推理引擎 |\n",
    "| 适用场景 | 多客户端、生产环境 | 单机批量推理、实验 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 1: 初始化 vLLM 离线推理\n",
    "\n",
    "这会直接加载模型到 GPU，无需服务器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from vllm_dspy_adapter import vLLMOffline\n",
    "\n",
    "# 初始化 vLLM 离线推理引擎\n",
    "# 注意：第一次运行会加载模型，需要几分钟\n",
    "lm = vLLMOffline(\n",
    "    model=\"/home/yuhan/model_zoo/Qwen3-8B\",  # 模型路径\n",
    "    temperature=0.6,\n",
    "    max_tokens=15000,\n",
    "    top_p=0.95,\n",
    "    gpu_memory_utilization=0.9,  # GPU 显存利用率\n",
    "    tensor_parallel_size=1,      # 单GPU设为1，多GPU可设为GPU数量\n",
    ")\n",
    "\n",
    "# 配置 DSPy 使用这个语言模型\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"\\n✓ vLLM 离线推理引擎已就绪！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 2: 测试基础推理\n",
    "\n",
    "验证模型能够正常工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个推理测试\n",
    "result = lm(\"1+1等于几？请只回答数字。\")\n",
    "print(f\"问题: 1+1等于几？\")\n",
    "print(f\"回答: {result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 3: 批量推理（数据并行）\n",
    "\n",
    "vLLM 的核心优势：自动批处理多个请求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 准备多个问题\n",
    "questions = [\n",
    "    \"1+1=?\",\n",
    "    \"什么是深度学习？\",\n",
    "    \"解释一下transformer架构。\",\n",
    "    \"Python中如何定义函数？\",\n",
    "    \"什么是注意力机制？\",\n",
    "]\n",
    "\n",
    "# 批量推理\n",
    "start_time = time.time()\n",
    "results = lm.batch_generate(questions, max_tokens=200)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"批量推理 {len(questions)} 个问题，耗时: {end_time - start_time:.2f} 秒\")\n",
    "print(f\"平均每个问题: {(end_time - start_time) / len(questions):.2f} 秒\\n\")\n",
    "\n",
    "# 显示结果\n",
    "for i, (q, a) in enumerate(zip(questions, results), 1):\n",
    "    print(f\"[{i}] 问题: {q}\")\n",
    "    print(f\"    回答: {a[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 4: 加载 Benchmark\n",
    "\n",
    "使用 AIME 数学基准测试（与原 notebook 相同）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gepa_artifact.benchmarks.AIME import benchmark as aime_metas\n",
    "\n",
    "# 加载 benchmark\n",
    "cur_meta = aime_metas\n",
    "bench = cur_meta[0].benchmark()\n",
    "\n",
    "print(f\"训练集大小: {len(bench.train_set)}\")\n",
    "print(f\"验证集大小: {len(bench.val_set)}\")\n",
    "print(f\"测试集大小: {len(bench.test_set)}\")\n",
    "\n",
    "# 查看一个样本\n",
    "print(\"\\n示例问题:\")\n",
    "print(bench.test_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 5: 加载 Program\n",
    "\n",
    "这是用于解决问题的 DSPy 程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预定义的程序\n",
    "program = cur_meta[0].program[0]\n",
    "print(\"Program 结构:\")\n",
    "print(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 6: 评估 Base Program\n",
    "\n",
    "使用多线程并行评估（num_threads=80 利用 vLLM 的批处理能力）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建评估器\n",
    "evaluate = dspy.Evaluate(\n",
    "    devset=bench.test_set,\n",
    "    metric=cur_meta[0].metric,\n",
    "    num_threads=80,  # 多线程评估，vLLM 会自动批处理\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    max_errors=100 * len(bench.test_set)\n",
    ")\n",
    "\n",
    "# 开始评估\n",
    "print(\"开始评估 base program...\")\n",
    "base_score = evaluate(program)\n",
    "print(f\"\\n✓ Base Program 得分: {base_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 7: 使用 GEPA 优化（可选）\n",
    "\n",
    "使用 GEPA 优化器来改进程序性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from gepa_artifact.gepa.gepa import GEPA\n",
    "from gepa_artifact.utils.capture_stream_logger import Logger\n",
    "\n",
    "# 创建运行目录\n",
    "runs_dir = os.path.join(os.getcwd(), \"runs\", time.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "os.makedirs(runs_dir, exist_ok=True)\n",
    "\n",
    "gepa_logger = Logger(os.path.join(runs_dir, \"run_log.txt\"))\n",
    "\n",
    "# 定义 feedback 函数\n",
    "if cur_meta[0].feedback_fn_maps is None or cur_meta[0].feedback_fn_maps[0] is None:\n",
    "    def feedback_func(predictor_output, predictor_inputs, module_inputs, module_outputs, captured_trace):\n",
    "        pred = cur_meta[0].metric_with_feedback(module_inputs, module_outputs, None)\n",
    "        return {\n",
    "            \"feedback_score\": pred.score,\n",
    "            \"feedback_text\": pred.feedback,\n",
    "        }\n",
    "    feedback_fn_map = {k: feedback_func for k, v in program.named_predictors()}\n",
    "else:\n",
    "    feedback_fn_map = cur_meta[0].feedback_fn_maps[0]\n",
    "\n",
    "# 创建 GEPA 优化器\n",
    "optimizer = GEPA(\n",
    "    named_predictor_to_feedback_fn_map=feedback_fn_map,\n",
    "    knowledgebase_qe=None,\n",
    "    metric=cur_meta[0].metric,\n",
    "    run_linearized_gepa=False,\n",
    "    use_merge=True,\n",
    "    set_for_merge_minibatch='val',\n",
    "    track_scores_on='val',\n",
    "    max_metric_calls=700,\n",
    "    run_dir=runs_dir,\n",
    "    logger=gepa_logger,\n",
    "    num_threads=40\n",
    ")\n",
    "\n",
    "print(\"GEPA 优化器已创建\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行优化\n",
    "print(\"开始 GEPA 优化...\")\n",
    "optimized_program = optimizer.compile(\n",
    "    cur_meta[0].program[0],\n",
    "    trainset=bench.train_set,\n",
    "    valset=bench.val_set[:len(bench.val_set)//2],\n",
    ")\n",
    "print(\"\\n✓ 优化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 8: 评估优化后的 Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估优化后的程序\n",
    "print(\"评估优化后的 program...\")\n",
    "optimized_score = evaluate(optimized_program)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"Base Program 得分: {base_score}\")\n",
    "print(f\"优化后 Program 得分: {optimized_score}\")\n",
    "print(f\"提升: {optimized_score - base_score:.2%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 9: 查看优化后的 Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印 GEPA 发现的优化指令\n",
    "for name, pred in optimized_program.named_predictors():\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Predictor: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Optimized Instructions:\")\n",
    "    print(pred.signature.instructions)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 使用 vLLM 离线推理的关键点：\n",
    "\n",
    "1. **无需服务器**：直接在代码中加载模型\n",
    "2. **自动批处理**：vLLM 自动优化批量推理\n",
    "3. **多线程支持**：`dspy.Evaluate` 的 `num_threads` 参数配合 vLLM 的批处理实现高效并行\n",
    "4. **完全兼容**：与现有的 DSPy 和 GEPA 代码无缝集成\n",
    "\n",
    "### 性能对比（参考）：\n",
    "\n",
    "- **服务器模式**：每个请求需要 HTTP 开销，适合多客户端场景\n",
    "- **离线模式**：无网络开销，批处理优化，适合单机大规模评估\n",
    "\n",
    "### 何时使用离线模式：\n",
    "\n",
    "✅ 运行 benchmark 评估  \n",
    "✅ 批量处理大量样本  \n",
    "✅ GEPA 优化器训练  \n",
    "✅ 单机实验和研究  \n",
    "\n",
    "### 何时使用服务器模式：\n",
    "\n",
    "✅ 多个客户端同时使用  \n",
    "✅ 生产环境部署  \n",
    "✅ 需要 API 接口  \n",
    "✅ 跨机器访问  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
